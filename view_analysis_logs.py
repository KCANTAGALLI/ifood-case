"""
Visualizador de Logs das An√°lises NYC Taxi
==========================================

Script para visualizar de forma amig√°vel os logs JSON gerados das an√°lises obrigat√≥rias.
"""

import json
import os
import glob
from typing import Dict, Any
from datetime import datetime


class AnalysisLogViewer:
    """Visualizador dos logs de an√°lise."""
    
    def __init__(self, logs_dir: str = "analysis_logs"):
        """
        Inicializa o visualizador.
        
        Args:
            logs_dir: Diret√≥rio contendo os logs JSON
        """
        self.logs_dir = logs_dir
    
    def find_latest_logs(self) -> Dict[str, str]:
        """
        Encontra os logs mais recentes.
        
        Returns:
            Dict com os caminhos dos logs mais recentes
        """
        if not os.path.exists(self.logs_dir):
            return {}
        
        # Buscar arquivos por tipo
        monthly_files = glob.glob(os.path.join(self.logs_dir, "monthly_analysis_log_*.json"))
        hourly_files = glob.glob(os.path.join(self.logs_dir, "hourly_analysis_log_*.json"))
        consolidated_files = glob.glob(os.path.join(self.logs_dir, "consolidated_analysis_report_*.json"))
        
        # Pegar os mais recentes (√∫ltimo na lista ordenada)
        latest_logs = {}
        if monthly_files:
            latest_logs['monthly'] = sorted(monthly_files)[-1]
        if hourly_files:
            latest_logs['hourly'] = sorted(hourly_files)[-1]
        if consolidated_files:
            latest_logs['consolidated'] = sorted(consolidated_files)[-1]
            
        return latest_logs
    
    def load_json_log(self, filepath: str) -> Dict[str, Any]:
        """
        Carrega um arquivo JSON de log.
        
        Args:
            filepath: Caminho para o arquivo JSON
            
        Returns:
            Dict com o conte√∫do do log
        """
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"Erro ao carregar {filepath}: {e}")
            return {}
    
    def display_monthly_analysis(self, log_data: Dict[str, Any]) -> None:
        """Exibe a an√°lise mensal de forma formatada."""
        
        print("\n" + "="*80)
        print("üìä AN√ÅLISE 1: M√âDIA DE VALOR TOTAL POR M√äS")
        print("="*80)
        
        print(f"\nüéØ Pergunta:")
        print("   Qual a m√©dia de valor total (total_amount) recebido em um m√™s")
        print("   considerando todos os yellow t√°xis da frota?")
        
        print(f"\nüìã Detalhes:")
        print(f"   ‚Ä¢ Per√≠odo: {log_data.get('period', 'N/A')}")
        print(f"   ‚Ä¢ Fonte: {log_data.get('data_source', 'N/A')}")
        print(f"   ‚Ä¢ Execu√ß√£o: {log_data.get('execution_timestamp', 'N/A')}")
        
        print(f"\nüîç Metodologia:")
        methodology = log_data.get('methodology', {})
        print(f"   ‚Ä¢ M√©trica: {methodology.get('metric', 'N/A')}")
        print(f"   ‚Ä¢ N√≠vel: {methodology.get('aggregation_level', 'N/A')}")
        print(f"   ‚Ä¢ Agrupamento: {methodology.get('group_by', 'N/A')}")
        
        print(f"\nüìà Resultados por M√™s:")
        results = log_data.get('results', [])
        for result in results:
            print(f"   ‚Ä¢ {result['month_name']:>9}: R$ {result['avg_total_amount']:>7.2f} "
                  f"({result['total_trips']:>9,} viagens)")
        
        print(f"\nüìä Resumo Estat√≠stico:")
        summary = log_data.get('summary', {})
        print(f"   ‚Ä¢ M√©dia Geral: R$ {summary.get('overall_average', 0):.2f}")
        print(f"   ‚Ä¢ Total de Viagens: {summary.get('total_trips_analyzed', 0):,}")
        print(f"   ‚Ä¢ Maior Valor: {summary.get('highest_month', {}).get('month', 'N/A')} "
              f"(R$ {summary.get('highest_month', {}).get('value', 0):.2f})")
        print(f"   ‚Ä¢ Menor Valor: {summary.get('lowest_month', {}).get('month', 'N/A')} "
              f"(R$ {summary.get('lowest_month', {}).get('value', 0):.2f})")
        print(f"   ‚Ä¢ Tend√™ncia: {summary.get('trend', 'N/A')}")
        
        print(f"\nüìã Qualidade dos Dados:")
        quality = log_data.get('data_quality', {})
        print(f"   ‚Ä¢ Registros Processados: {quality.get('records_processed', 0):,}")
        print(f"   ‚Ä¢ Registros Filtrados: {quality.get('records_filtered_out', 0):,}")
        print(f"   ‚Ä¢ Completude: {quality.get('data_completeness', 0):.1f}%")
        print(f"   ‚Ä¢ Outliers Removidos: {quality.get('outliers_removed', 0):,}")
    
    def display_hourly_analysis(self, log_data: Dict[str, Any]) -> None:
        """Exibe a an√°lise hor√°ria de forma formatada."""
        
        print("\n" + "="*80)
        print("üìä AN√ÅLISE 2: M√âDIA DE PASSAGEIROS POR HORA (MAIO)")
        print("="*80)
        
        print(f"\nüéØ Pergunta:")
        print("   Qual a m√©dia de passageiros (passenger_count) por cada hora do dia")
        print("   que pegaram t√°xi no m√™s de maio considerando todos os t√°xis da frota?")
        
        print(f"\nüìã Detalhes:")
        print(f"   ‚Ä¢ Per√≠odo: {log_data.get('period', 'N/A')}")
        print(f"   ‚Ä¢ Fonte: {log_data.get('data_source', 'N/A')}")
        print(f"   ‚Ä¢ Execu√ß√£o: {log_data.get('execution_timestamp', 'N/A')}")
        
        print(f"\nüìà Resultados por Hora:")
        results = log_data.get('results', [])
        
        # Dividir em per√≠odos para melhor visualiza√ß√£o
        periods = [
            ("Madrugada (00h-05h)", results[0:6]),
            ("Manh√£ (06h-11h)", results[6:12]),
            ("Tarde (12h-17h)", results[12:18]),
            ("Noite (18h-23h)", results[18:24])
        ]
        
        for period_name, period_data in periods:
            print(f"\n   {period_name}:")
            for result in period_data:
                print(f"      {result['hour_display']:>8}: {result['avg_passenger_count']:.2f} passageiros "
                      f"({result['total_trips']:>6,} viagens)")
        
        print(f"\nüìä Resumo Estat√≠stico:")
        summary = log_data.get('summary', {})
        print(f"   ‚Ä¢ M√©dia Geral: {summary.get('overall_average', 0):.2f} passageiros/viagem")
        print(f"   ‚Ä¢ Total de Viagens: {summary.get('total_trips_analyzed', 0):,}")
        print(f"   ‚Ä¢ Pico: {summary.get('peak_hour', {}).get('hour', 'N/A')} "
              f"({summary.get('peak_hour', {}).get('value', 0):.2f} passageiros)")
        print(f"   ‚Ä¢ Menor: {summary.get('lowest_hour', {}).get('hour', 'N/A')} "
              f"({summary.get('lowest_hour', {}).get('value', 0):.2f} passageiros)")
        
        print(f"\nüïê Padr√µes Identificados:")
        patterns = log_data.get('patterns', {})
        for pattern_name, pattern_data in patterns.items():
            print(f"   ‚Ä¢ {pattern_name.replace('_', ' ').title()}: "
                  f"{pattern_data.get('hours', 'N/A')} - "
                  f"{pattern_data.get('avg_passengers', 0):.2f} passageiros")
    
    def display_consolidated_report(self, log_data: Dict[str, Any]) -> None:
        """Exibe o relat√≥rio consolidado."""
        
        print("\n" + "="*80)
        print("üìã RELAT√ìRIO CONSOLIDADO - AN√ÅLISES OBRIGAT√ìRIAS")
        print("="*80)
        
        project_info = log_data.get('project_info', {})
        print(f"\nüéØ Informa√ß√µes do Projeto:")
        print(f"   ‚Ä¢ Nome: {project_info.get('name', 'N/A')}")
        print(f"   ‚Ä¢ Reposit√≥rio: {project_info.get('repository', 'N/A')}")
        print(f"   ‚Ä¢ Fonte dos Dados: {project_info.get('data_source', 'N/A')}")
        print(f"   ‚Ä¢ Per√≠odo: {project_info.get('period_analyzed', 'N/A')}")
        print(f"   ‚Ä¢ Tecnologias: {', '.join(project_info.get('technology_stack', []))}")
        
        print(f"\nüîç Principais Insights:")
        insights = log_data.get('key_insights', [])
        for i, insight in enumerate(insights, 1):
            print(f"   {i}. {insight}")
        
        print(f"\nüìä Resumo da Qualidade dos Dados:")
        quality = log_data.get('data_quality_summary', {})
        print(f"   ‚Ä¢ Total de Registros: {quality.get('total_records_processed', 0):,}")
        print(f"   ‚Ä¢ Completude Geral: {quality.get('overall_completeness', 0):.1f}%")
        print(f"   ‚Ä¢ Valida√ß√£o: {'‚úÖ Aprovada' if quality.get('data_validation_passed') else '‚ùå Reprovada'}")
        
        colunas = quality.get('mandatory_columns_present', [])
        print(f"   ‚Ä¢ Colunas Obrigat√≥rias: {', '.join(colunas)}")
        
        print(f"\n‚öôÔ∏è Metadados de Execu√ß√£o:")
        metadata = log_data.get('execution_metadata', {})
        print(f"   ‚Ä¢ Vers√£o do Pipeline: {metadata.get('pipeline_version', 'N/A')}")
        print(f"   ‚Ä¢ Vers√£o do Spark: {metadata.get('spark_version', 'N/A')}")
        print(f"   ‚Ä¢ Ambiente: {metadata.get('execution_environment', 'N/A')}")
        print(f"   ‚Ä¢ Tempo de Processamento: {metadata.get('processing_time_seconds', 0):,} segundos")
        print(f"   ‚Ä¢ Uso de Mem√≥ria: {metadata.get('memory_usage_gb', 0):.1f} GB")
    
    def display_all_logs(self) -> None:
        """Exibe todos os logs encontrados."""
        
        print("NYC TAXI ANALYSIS - VISUALIZADOR DE LOGS")
        print("=" * 50)
        
        latest_logs = self.find_latest_logs()
        
        if not latest_logs:
            print("‚ùå Nenhum log encontrado no diret√≥rio:", self.logs_dir)
            return
        
        print(f"üìÅ Diret√≥rio: {self.logs_dir}")
        print(f"üìÖ Logs encontrados: {len(latest_logs)}")
        
        # Exibir an√°lise mensal
        if 'monthly' in latest_logs:
            monthly_data = self.load_json_log(latest_logs['monthly'])
            if monthly_data:
                self.display_monthly_analysis(monthly_data)
        
        # Exibir an√°lise hor√°ria
        if 'hourly' in latest_logs:
            hourly_data = self.load_json_log(latest_logs['hourly'])
            if hourly_data:
                self.display_hourly_analysis(hourly_data)
        
        # Exibir relat√≥rio consolidado
        if 'consolidated' in latest_logs:
            consolidated_data = self.load_json_log(latest_logs['consolidated'])
            if consolidated_data:
                self.display_consolidated_report(consolidated_data)
        
        print("\n" + "="*80)
        print("‚úÖ VISUALIZA√á√ÉO COMPLETA DOS LOGS")
        print("="*80)
        print(f"üìÑ Arquivos processados:")
        for log_type, filepath in latest_logs.items():
            print(f"   ‚Ä¢ {log_type.title()}: {os.path.basename(filepath)}")


def main():
    """Fun√ß√£o principal."""
    viewer = AnalysisLogViewer()
    viewer.display_all_logs()


if __name__ == "__main__":
    main()
